# Optimizando la ejecuci√≥n de procesamiento de √≥rdenes en Python

## üìå Problema

El programa original generaba **1,000 √≥rdenes falsas** y las procesaba una por una.  
Cada orden simulaba guardarse en una base de datos mediante un `time.sleep(random.uniform(0, 1))`, lo que introduc√≠a una espera de hasta 1 segundo por cada orden.

Esto generaba un **tiempo total de ejecuci√≥n de alrededor de 9 minutos**, ya que el procesamiento era **secuencial** y no aprovechaba la capacidad de realizar varias tareas al mismo tiempo.

---

## ‚ö° Soluci√≥n

### ¬øPor d√≥nde se atac√≥?

El cuello de botella no estaba en la CPU, sino en la **espera de I/O** (simulada con `sleep`).  
Por eso se atac√≥ el problema usando **hilos (Threading)** en lugar de procesos, ya que los hilos son ideales para este tipo de tareas I/O-bound.  
El **GIL de Python** no afecta aqu√≠, porque durante el `sleep` se libera y otros hilos pueden avanzar.

---

### ¬øQu√© parte del c√≥digo se reemplaz√≥ y por qu√©?

- **Antes**:  
  Se usaba un bucle `for` que recorr√≠a la lista de √≥rdenes y llamaba directamente a `__fake_save_on_db`, bloqueando la ejecuci√≥n hasta que terminaba cada `sleep`.

  ```python
  def process_orders(self):
      for order in self.__orders:
          self.__fake_save_on_db(order=order)
          self.__orders_processed += 1
          ...
  ```

- **Despu√©s**:
  Se reemplaz√≥ este bucle secuencial por un **ThreadPoolExecutor**, que permite ejecutar m√∫ltiples llamadas a `__fake_save_on_db` en paralelo.
  De esta forma, mientras un hilo est√° en `sleep`, otros pueden seguir avanzando.

  ```python
  from concurrent.futures import ThreadPoolExecutor, as_completed

  def process_orders(self, workers=50):
      with ThreadPoolExecutor(max_workers=workers) as executor:
          futures = [executor.submit(self.__fake_save_on_db, order) for order in self.__orders]

          for future in as_completed(futures):
              result = future.result()
              self.__orders_processed += 1
              ...
  ```

---

## üöÄ Resultados

- Tiempo original: **\~9 minutos**
- Tiempo optimizado con hilos (`max_workers=50`): **\~20 segundos**

La optimizaci√≥n se logr√≥ al **ejecutar √≥rdenes en paralelo con hilos**, aprovechando mejor los tiempos de espera y reduciendo dr√°sticamente el tiempo total de ejecuci√≥n.
